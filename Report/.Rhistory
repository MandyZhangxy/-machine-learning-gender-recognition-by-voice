library("caret")
library("pROC")
library(caTools)
library(class)
library(tidyr)
library(dplyr)
library("stats")
voice = read.csv("../data/voice.csv")
scaled_voice = read.csv("../data/scaled_voice.csv")
gender = voice %>% group_by(label)
gender = gender %>% summarise(n=n())
ggplot(gender, aes(label, n, color = label, fill = label)) + geom_bar(stat = 'identity',alpha=0.3,width=0.5)+
geom_text(aes(label = n), vjust=-0.3, size = 5) +
labs(x = "Gender", y = "Count", size = 3) + ggtitle("Number of People in Each Gender") + theme_light()
pair = gather(voice[, 1:20])
set.seed(1)
ind = sample.split(Y = scaled_voice["label"], SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[!ind, ]
ind = sample.split(Y = scaled_voice["label"], SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[!ind, ]
test = scaled_voice[-ind, ]
ind = sample.split(Y = scaled_voice["label"], SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[-ind, ]
train = data.frame(train)
test= data.frame(test)
bestmry = tuneRF(x = train[, -21], train$label,
ntreeTry = 300, stepFactor = 1.5, improve = 0.001,
trace = TRUE, plot = TRUE, importance = TRUE)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
bestmry = data.frame(bestmry)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
print(paste("Therefore, the best number of variables at each split is ", bestmry))
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
importance = data.frame(importance(trainingmodel))
variables = rownames(importance)
importance$variables = variables
varImpPlot(trainingmodel)
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("\n\nImportance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15))
selected = importance$variables[order(importance$MeanDecreaseGini, decreasing = T)[1:7]]
selected = append(selected, "label")
train = train[ , names(train) %in% selected]
test = test[ , names(test) %in% selected]
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
predictionWithClass = predict(trainingmodel, test, type = "class")
t = table(predictions = predictionWithClass, actual = test$label)
t
print("In this model, the accuracy rate is:")
sum(diag(t))/sum(t)
predictionWithProbs = predict(trainingmodel, test, type = "prob")
plot(roc(test$label, predictionWithProbs[ ,2]), main = "Random Forest AUC/ROC")
CM = confusionMatrix(predictionWithClass, test$label)
print(CM)
getwd()
voice = read.csv("../data/voice.csv",stringsAsFactors = FALSE)
library(dplyr)
gender = voice %>% group_by(label)
gender = gender %>% summarise(n=n())
pdf("figures/count in gender.pdf", width = 16.5, height = 9.5)
ylim <- c(0, 1.1*max(gender$n))
g = barplot(gender$n, ylab = "Count", xlab = "gender",
names.arg = gender$label, main = "Number of People in Each Gender",border="red",
col="blue",ylim = c(0, 1.1*max(gender$n)),width = 0.1,
density=10)
text(x = g, y = gender$n, label = gender$n, pos = 3, cex = 1, col = "red")
dev.off()
pdf("../figures/count in gender.pdf", width = 16.5, height = 9.5)
ylim <- c(0, 1.1*max(gender$n))
g = barplot(gender$n, ylab = "Count", xlab = "gender",
names.arg = gender$label, main = "Number of People in Each Gender",border="red",
col="blue",ylim = c(0, 1.1*max(gender$n)),width = 0.1,
density=10)
text(x = g, y = gender$n, label = gender$n, pos = 3, cex = 1, col = "red")
dev.off()
pdf("../figures/count in gender.pdf", width = 16.5, height = 9.5)
ggplot(gender, aes(label, n, color = label, fill = label)) + geom_bar(stat = 'identity',alpha=0.3,width=0.5)+
geom_text(aes(label = n), vjust=-0.3, size = 5) +
labs(x = "Gender", y = "Count", size = 3) + ggtitle("Number of People in Each Gender") + theme_light()
dev.off()
library(tidyr)
library(ggplot2)
pair = gather(voice[, 1:20])
pdf("../figures/all variables density.pdf", width = 16.5, height = 9.5)
ggplot(pair, aes(value)) + facet_wrap(~ key, scales = "free") + geom_density()+
labs(x = "feature in each column") + ggtitle("Density of all variables")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1))
dev.off()
pdf("../figures/Modulation Index vs. Mean Frequency.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=modindx, y=meanfreq, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "Modulation Index", y = "Mean Frequency") + ggtitle("Modulation Index vs. Mean Frequency")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/Skew vs. Kurtosis.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(skew, kurt, group=label)) + geom_line(aes(colour = label), size = 0.7,alpha=0.9) +
labs(x = "Skew", y = "Kurtosis", size = 3) + ggtitle("Skew vs. Kurtosis")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() + scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/sd_vs_meanfreq.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=sd, y=meanfreq, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "Standard Deviation of Frequency", y = "Mean Frequency") + ggtitle("Standard Deviation vs. Mean Frequency")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/meafun_vs_meanfreq.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=meanfun, y=meanfreq, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "Average of Fundmental Frequency", y = "Mean Frequency") + ggtitle("Average of Fundmental Frequency vs. Mean Frequency")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/meanfun_vs_sd.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=meanfun, y=sd, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "Average of Fundmental Frequency", y = "Standard Deviation") + ggtitle("Average of Fundmental Frequency vs. Standard Deviation")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/1stquant_vs_IRQ.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=Q25, y=IQR, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "First Quantile", y = "Interquantile") + ggtitle("First Quantile vs. Interquantile")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
pdf("../figures/Entropy_vs_flatness.pdf", width = 16.5, height = 9.5)
ggplot(voice, aes(x=sp.ent, y=sfm, group=label)) + geom_point(aes(colour = label), size = 1,alpha=0.55) +
labs(x = "Spectral Entropy", y = "Spectral Flatness") + ggtitle("Spectral Entropy vs. Spectral Flatness")+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold", size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x = element_text(vjust = 0.1, hjust = 0.1)) + theme_light() +  scale_color_hue(l=38, c=65)
dev.off()
scaled_voice = read.csv("../data/scaled_voice.csv")
library(caTools)
set.seed(1)
ind = sample.split(Y = scaled_voice$label, SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[!ind, ]
bestmry = tuneRF(x = train[, -21], train$label,
ntreeTry = 300, stepFactor = 1.5, improve = 0.001,
trace = TRUE, plot = TRUE, importance = TRUE)
bestmry = data.frame(bestmry)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
bestmry
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
importance = data.frame(importance(trainingmodel))
variables = rownames(importance)
importance$variables = variables
varImpPlot(trainingmodel)
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15))
pdf("../figures/importance.pdf", width = 16.5, height = 9.5)
varImpPlot(trainingmodel)
dev.off()
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = -90, hjust = 0))
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = 45, hjust = 0))
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = 90, hjust = 0))
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = 90, hjust = 0))
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = 75, hjust = 0))
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = -75, hjust = 0))
pdf("../figures/ggplotimportance.pdf", width = 16.5, height = 9.5)
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = -75, hjust = 0))
dev.off()
selected = importance$variables[order(importance$MeanDecreaseGini, decreasing = T)[1:7]]
selected = append(selected, "label")
train = train[ , names(train) %in% selected]
test = test[ , names(test) %in% selected]
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
write.csv(test, file = "../data/test.csv",row.names = FALSE)
write.csv(train, file = "../data/train.csv")
predictionWithClass = predict(trainingmodel, test, type = "class")
t = table(predictions = predictionWithClass, actual = test$label)
t
sum(diag(t))/sum(t)
predictionWithProbs = prediction(trainingmodel, test, type = "prob")
library("pROC")
predictionWithProbs = prediction(trainingmodel, test, type = "prob")
predictionWithProbs = predict(trainingmodel, test, type = "prob")
plot(roc(test$label, predictionWithProbs[ ,2]), main = "AUC/ROC")
pdf("../figures/roc_curve.pdf", width = 10.5, height = 9.5)
plot(roc(test$label, predictionWithProbs[ ,2]), main = "AUC/ROC")
dev.off()
voice = read.csv("../data/voice.csv")
scaled_voice = voice
set.seed(1)
ind = sample.split(Y = scaled_voice$label, SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[!ind, ]
bestmry = tuneRF(x = train[, -21], train$label,
ntreeTry = 300, stepFactor = 1.5, improve = 0.001,
trace = TRUE, plot = TRUE, importance = TRUE)
bestmry = data.frame(bestmry)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
bestmry
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
importance = data.frame(importance(trainingmodel))
variables = rownames(importance)
importance$variables = variables
varImpPlot(trainingmodel)
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = -75, hjust = 0))
selected = importance$variables[order(importance$MeanDecreaseGini, decreasing = T)[1:7]]
selected = append(selected, "label")
train = train[ , names(train) %in% selected]
test = test[ , names(test) %in% selected]
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
write.csv(test, file = "../data/test.csv",row.names = FALSE)
write.csv(train, file = "../data/train.csv")
predictionWithClass = predict(trainingmodel, test, type = "class")
t = table(predictions = predictionWithClass, actual = test$label)
t
sum(diag(t))/sum(t)
predictionWithProbs = predict(trainingmodel, test, type = "prob")
pdf("../figures/ggplotimportance.pdf", width = 16.5, height = 9.5)
ggplot(data = importance, aes(
x = reorder(variables, -MeanDecreaseGini),
y = MeanDecreaseGini)) + geom_bar(stat = 'identity',fill = "#FF6666",alpha=0.75) +
theme_light() + xlab("Variabels")+
theme(plot.title = element_text(hjust = 0.5))+
geom_text(aes(label = round(MeanDecreaseGini)), vjust=-0.3, size = 3)+
ggtitle("Importance of Variables in descending order") +
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15),
axis.text.x=element_text(angle = -75, hjust = 0))
dev.off()
pdf("../figures/importance.pdf", width = 16.5, height = 9.5)
varImpPlot(trainingmodel)
dev.off()
predictionWithClass = predict(trainingmodel, test, type = "class")
t = table(predictions = predictionWithClass, actual = test$label)
t
sum(diag(t))/sum(t)
predictionWithProbs = predict(trainingmodel, test, type = "prob")
plot(roc(test$label, predictionWithProbs[ ,2]), main = "AUC/ROC")
pdf("../figures/roc_curve.pdf", width = 10.5, height = 9.5)
plot(roc(test$label, predictionWithProbs[ ,2]), main = "AUC/ROC")
dev.off()
CM = confusionMatrix(predictionWithClass, test$label)
cm = as.data.frame(CM$table)
pdf("../figures/confusion_matrix.pdf", width = 16.5, height = 9.5)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15))
dev.off()
rfModel = trainingmodel;
save(rfModel, file = "../models/rfModel.rda")
varImpPlot(trainingmodel, ylab(size = 0.5))
print(x)
library("class")
voice = read.csv("../data/voice.csv")
test = read.csv("../data/test.csv")
knn_pred = knn(train = train[, -8], test = test[ ,-8], cl=train[, "label"], k=7, prob = TRUE)
plot(roc(test$label,as.numeric(knn_pred)), main = "KNN AUC/ROC")
print("The accuracy rate in KNN is:")
sum(knn_pred == test[, 8])/length(test[,8])
CM = confusionMatrix(knn_pred, test$label)
print(CM)
cm = as.data.frame(CM$table)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 5, vjust = 1),
axis.title.y = element_text(face = "bold", size = 5))
pdf("../figures/knn_roc.pdf", width = 16.5, height = 9.5)
plot(roc(test$label,as.numeric(knn_pred)), main = "KNN AUC/ROC")
dev.off()
pdf("../figures/knn_confusion_matrix.pdf", width = 16.5, height = 9.5)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15))
dev.off()
cm = as.data.frame(CM$table)
sum(knn_pred == test[, 8])/length(test[,8])
library(ggplot2)
logitmodel<- glm(label~.,family = binomial(link =  "logit"), train,control = list(maxit = 50))
?glm
pdf("../figures/logistic_roc.pdf", width = 16.5, height = 9.5)
plot(roc(test$label, predictionWithClass_lg), main = "AUC/ROC")
dev.off()
library("stats")
library("ggplot2")
library("caret")
numeric = ifelse(train$label == 'male',1,0)
logitmodel<- glm(label~.,family = binomial(link =  "logit"), train,control = list(maxit = 50))
summary(logitmodel)
logitmodel2<- glm(label~IQR+sp.ent+sfm+meanfun,family = binomial(link =  "logit"), train,control = list(maxit = 50))
summary(logitmodel2)
predictionWithClass_lg = predict(logitmodel2, test[-8],  type='response')
predictionWithClass_lg = ifelse(predictionWithClass_lg>0.5,1,0)
t = table(predictions= predictionWithClass_lg, actual = test$label)
t
# Accuracy metric/rate
sum(diag(t))/sum(t)
# ploting ROC curve and calculating AUC metric
pdf("../figures/logistic_roc.pdf", width = 16.5, height = 9.5)
plot(roc(test$label, predictionWithClass_lg), main = "AUC/ROC")
dev.off()
# plot confusion matrix
lg = predictionWithClass_lg
lg = factor(lg, levels = c(0,1), labels = c("female", "male"))
CM = confusionMatrix(lg, test$label)
print(CM)
cm = as.data.frame(CM$table)
pdf("../figures/logistic_confusion_matrix.pdf", width = 16.5, height = 9.5)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 5, vjust = 1),
axis.title.y = element_text(face = "bold", size = 5))
dev.off()
numeric = ifelse(train$label == 'male',1,0)
logitmodel<- glm(label~.,family = binomial(link =  "logit"), train,control = list(maxit = 50))
summary(logitmodel)
logitmodel2<- glm(label~IQR+sp.ent+sfm+meanfun+mode,family = binomial(link =  "logit"), train,control = list(maxit = 50))
summary(logitmodel2)
predictionWithClass_lg = predict(logitmodel2, test[-8],  type='response')
predictionWithClass_lg = ifelse(predictionWithClass_lg>0.5,1,0)
t = table(predictions= predictionWithClass_lg, actual = test$label)
t
# Accuracy metric/rate
sum(diag(t))/sum(t)
# ploting ROC curve and calculating AUC metric
pdf("../figures/logistic_roc.pdf", width = 16.5, height = 9.5)
plot(roc(test$label, predictionWithClass_lg), main = "AUC/ROC")
dev.off()
# plot confusion matrix
lg = predictionWithClass_lg
lg = factor(lg, levels = c(0,1), labels = c("female", "male"))
CM = confusionMatrix(lg, test$label)
print(CM)
cm = as.data.frame(CM$table)
pdf("../figures/logistic_confusion_matrix.pdf", width = 16.5, height = 9.5)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 10, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 5, vjust = 1),
axis.title.y = element_text(face = "bold", size = 5))
dev.off()
pdf("../figures/logistic_confusion_matrix.pdf", width = 16.5, height = 9.5)
ggplot(data = cm, mapping = aes(x = Reference, y = Prediction)) +
geom_tile(aes(fill = Freq), color = "white") +
scale_fill_gradient(low = "white", high = "#ffb5e9")  +
geom_text(aes(label = Freq),size = 7) + theme(legend.position = "none") +
ggtitle(paste("Confusion Matrix with Accuracy rate ", round(100*CM$overall[1],2), "%"))+
theme(plot.title = element_text(face = "bold", size = 18, hjust = 0.5),
axis.title.x = element_text(face = "bold",size = 15, vjust = 1),
axis.title.y = element_text(face = "bold", size = 15))
dev.off()
?gather()
paste(sum(diag(t))/sum(t)*100,"%")
paste(round(sum(diag(t))/sum(t)*100,2),"%")
sum(knn_pred == test[, 8])/length(test[,8])
paste(round(sum(knn_pred == test[, 8])/length(test[,8])*100,2),"%")
paste(round(sum(diag(t))/sum(t)*100,2),"%")
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
bestmry = tuneRF(x = train[, -21], train$label,
ntreeTry = 300, stepFactor = 1.5, improve = 0.001,
trace = TRUE, plot = TRUE, importance = TRUE)
bestmry = data.frame(bestmry)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
print(paste("Therefore, based on the plot above, the best number of variables at each split is", bestmry))
voice = read.csv("../data/voice.csv")
scaled_voice = voice
head(scaled_voice)
set.seed(1)
ind = sample.split(Y = scaled_voice$label, SplitRatio = 0.7)
train = scaled_voice[ind, ]
test = scaled_voice[!ind, ]
bestmry = tuneRF(x = train[, -21], train$label,
ntreeTry = 300, stepFactor = 1.5, improve = 0.001,
trace = TRUE, plot = TRUE, importance = TRUE)
bestmry = data.frame(bestmry)
bestmry = bestmry$mtry[which.min(bestmry$OOBError)]
bestmry
trainingmodel = randomForest(label~., data = train, mtry = bestmry, ntree = 350)
importance = data.frame(importance(trainingmodel))
variables = rownames(importance)
importance$variables = variables
selected = importance$variables[order(importance$MeanDecreaseGini, decreasing = T)[1:7]]
selected = append(selected, "label")
selected
